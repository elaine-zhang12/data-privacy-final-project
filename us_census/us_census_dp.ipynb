{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Census Income Differential Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance\n",
    "from opendp.mod import enable_features\n",
    "from opendp.measurements import make_laplace\n",
    "from opendp.domains import atom_domain\n",
    "from opendp.metrics import absolute_distance\n",
    "enable_features(\"contrib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census = pd.read_csv('../data/adult.csv')\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data - Remove \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education.num        0\n",
      "marital.status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital.gain         0\n",
      "capital.loss         0\n",
      "hours.per.week       0\n",
      "native.country     583\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "question_mark_counts = (df_census == \"?\").sum()\n",
    "print(question_mark_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elzha\\AppData\\Local\\Temp\\ipykernel_20864\\2381018209.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df_census[~df_census.applymap(lambda x: str(x).strip() == \"?\").any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_census[~df_census.applymap(lambda x: str(x).strip() == \"?\").any(axis=1)]\n",
    "df_cleaned = df_cleaned.sample(n=5000, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Epsilon Values and Add DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting values for epsilon\n",
    "# Low ε (e.g., 0.1, 0.5) → More noise, stronger privacy, but lower accuracy.\n",
    "# High ε (e.g., 5, 10) → Less noise, higher accuracy, but weaker privacy.\n",
    "\n",
    "age = df_cleaned[\"age\"].astype(float).tolist()\n",
    "hours_per_week = df_cleaned[\"hours.per.week\"].astype(float).tolist()\n",
    "education_num = df_cleaned[\"education.num\"].astype(float).tolist()\n",
    "capital_gain = df_cleaned[\"capital.gain\"].astype(float).tolist()\n",
    "capital_loss = df_cleaned[\"capital.loss\"].astype(float).tolist()\n",
    "\n",
    "delta_1 = np.max(np.abs(np.diff(np.sort(age)))) \n",
    "delta_2 = np.max(np.abs(np.diff(np.sort(hours_per_week))))\n",
    "delta_3 = np.max(np.abs(np.diff(np.sort(education_num))))\n",
    "delta_4 = np.max(np.abs(np.diff(np.sort(capital_gain))))\n",
    "delta_5 = np.max(np.abs(np.diff(np.sort(capital_loss))))\n",
    "\n",
    "epsilon_values = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "results_age = {}\n",
    "results_hours_per_week = {}\n",
    "results_education_num = {}\n",
    "results_capital_gain = {}\n",
    "results_capital_loss = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding dp to age\n",
    "for epsilon in epsilon_values:\n",
    "    scale = delta_1 / epsilon\n",
    "    laplace_mechanism = make_laplace(\n",
    "        input_domain=atom_domain(T=float),\n",
    "        input_metric=absolute_distance(T=float),\n",
    "        scale=scale\n",
    "    )\n",
    "    dp_samples = np.array([[laplace_mechanism(x) for x in age] for _ in range(10)])\n",
    "    dp_age = np.mean(dp_samples, axis=0)\n",
    "    mae = np.mean(np.abs(dp_age - age))\n",
    "    stability = np.mean(np.std(dp_samples, axis=0))  \n",
    "    noise_variance = np.var(dp_samples - age, axis=0).mean()\n",
    "    emd = wasserstein_distance(age, dp_age)\n",
    "    results_age[epsilon] = {\"dp_values\": dp_age, \"mae\": mae, \"emd\": emd, \"stability\": stability,\n",
    "        \"noise_variance\": noise_variance}\n",
    "\n",
    "# adding dp for hours per week\n",
    "for epsilon in epsilon_values:\n",
    "    scale = delta_2 / epsilon\n",
    "    laplace_mechanism = make_laplace(\n",
    "        input_domain=atom_domain(T=float),\n",
    "        input_metric=absolute_distance(T=float),\n",
    "        scale=scale\n",
    "    )\n",
    "    dp_samples = np.array([[laplace_mechanism(x) for x in hours_per_week] for _ in range(10)])\n",
    "    dp_hours_per_week = np.mean(dp_samples, axis=0)\n",
    "    mae = np.mean(np.abs(dp_hours_per_week - hours_per_week))\n",
    "    stability = np.mean(np.std(dp_samples, axis=0))  \n",
    "    noise_variance = np.var(dp_samples - hours_per_week, axis=0).mean()\n",
    "    emd = wasserstein_distance(hours_per_week, dp_hours_per_week)\n",
    "    results_hours_per_week[epsilon] = {\"dp_values\": dp_hours_per_week, \"mae\": mae, \"emd\": emd, \"stability\": stability,\n",
    "        \"noise_variance\": noise_variance}\n",
    "\n",
    "# adding dp for education num\n",
    "for epsilon in epsilon_values:\n",
    "    scale = delta_3 / epsilon\n",
    "    laplace_mechanism = make_laplace(\n",
    "        input_domain=atom_domain(T=float),\n",
    "        input_metric=absolute_distance(T=float),\n",
    "        scale=scale\n",
    "    )\n",
    "    dp_samples = np.array([[laplace_mechanism(x) for x in education_num] for _ in range(10)])\n",
    "    dp_education_num = np.mean(dp_samples, axis=0)\n",
    "    mae = np.mean(np.abs(dp_education_num - education_num))\n",
    "    stability = np.mean(np.std(dp_samples, axis=0))  \n",
    "    noise_variance = np.var(dp_samples - education_num, axis=0).mean()\n",
    "    emd = wasserstein_distance(education_num, dp_education_num)\n",
    "    results_education_num[epsilon] = {\"dp_values\": dp_education_num, \"mae\": mae, \"emd\": emd, \"stability\": stability,\n",
    "        \"noise_variance\": noise_variance}\n",
    "\n",
    "# adding dp for capital gain\n",
    "for epsilon in epsilon_values:\n",
    "    scale = delta_4 / epsilon\n",
    "    laplace_mechanism = make_laplace(\n",
    "        input_domain=atom_domain(T=float),\n",
    "        input_metric=absolute_distance(T=float),\n",
    "        scale=scale\n",
    "    )\n",
    "    dp_samples = np.array([[laplace_mechanism(x) for x in capital_gain] for _ in range(10)])\n",
    "    dp_capital_gain = np.mean(dp_samples, axis=0)\n",
    "    mae = np.mean(np.abs(dp_capital_gain - capital_gain))\n",
    "    stability = np.mean(np.std(dp_samples, axis=0))  \n",
    "    noise_variance = np.var(dp_samples - capital_gain, axis=0).mean()\n",
    "    emd = wasserstein_distance(capital_gain, dp_capital_gain)\n",
    "    results_capital_gain[epsilon] = {\"dp_values\": dp_capital_gain, \"mae\": mae, \"emd\": emd, \"stability\": stability,\n",
    "        \"noise_variance\": noise_variance}\n",
    "\n",
    "# adding dp for capital loss\n",
    "for epsilon in epsilon_values:\n",
    "    scale = delta_5 / epsilon\n",
    "    laplace_mechanism = make_laplace(\n",
    "        input_domain=atom_domain(T=float),\n",
    "        input_metric=absolute_distance(T=float),\n",
    "        scale=scale\n",
    "    )\n",
    "    dp_samples = np.array([[laplace_mechanism(x) for x in capital_loss] for _ in range(10)])\n",
    "    dp_capital_loss = np.mean(dp_samples, axis=0)\n",
    "    mae = np.mean(np.abs(dp_capital_loss - capital_loss))\n",
    "    stability = np.mean(np.std(dp_samples, axis=0))  \n",
    "    noise_variance = np.var(dp_samples - capital_loss, axis=0).mean()\n",
    "    emd = wasserstein_distance(capital_loss, dp_capital_loss)\n",
    "    results_capital_loss[epsilon] = {\"dp_values\": dp_capital_loss, \"mae\": mae, \"emd\": emd, \"stability\": stability,\n",
    "        \"noise_variance\": noise_variance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results so I don't have to rerun\n",
    "import json\n",
    "\n",
    "# Save the results for each column as a JSON file\n",
    "for epsilon in results_age:\n",
    "    results_age[epsilon][\"dp_values\"] = results_age[epsilon][\"dp_values\"].tolist()\n",
    "    \n",
    "with open(\"../data/results_age.json\", \"w\") as f:\n",
    "    json.dump(results_age, f)\n",
    "\n",
    "for epsilon in results_hours_per_week:\n",
    "    results_hours_per_week[epsilon][\"dp_values\"] = results_hours_per_week[epsilon][\"dp_values\"].tolist()\n",
    "\n",
    "with open(\"../data/results_hours.json\", \"w\") as f:\n",
    "    json.dump(results_hours_per_week, f)\n",
    "\n",
    "for epsilon in results_education_num:\n",
    "    results_education_num[epsilon][\"dp_values\"] = results_education_num[epsilon][\"dp_values\"].tolist()\n",
    "\n",
    "with open(\"../data/results_education.json\", \"w\") as f:\n",
    "    json.dump(results_education_num, f)\n",
    "\n",
    "for epsilon in results_capital_gain:\n",
    "    results_capital_gain[epsilon][\"dp_values\"] = results_capital_gain[epsilon][\"dp_values\"].tolist()\n",
    "\n",
    "with open(\"../data/results_cap_gain.json\", \"w\") as f:\n",
    "    json.dump(results_capital_gain, f)\n",
    "\n",
    "for epsilon in results_capital_loss:\n",
    "    results_capital_loss[epsilon][\"dp_values\"] = results_capital_loss[epsilon][\"dp_values\"].tolist()\n",
    "\n",
    "with open(\"../data/results_cap_loss.json\", \"w\") as f:\n",
    "    json.dump(results_capital_loss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
